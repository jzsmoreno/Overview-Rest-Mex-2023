{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://drive.google.com/file/d/1kYjGK-X8u_C0vR7T5M1xyMYVgLVjDYc1/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.metrics import f1_score\n",
    "from numpy import ndarray\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dataset path\n",
    "path = \"./data/\"\n",
    "folder = \"raw/\"\n",
    "filename = \"Rest_Mex_Sentiment_Analysis_2023_Train.xlsx\"\n",
    "# reading the data\n",
    "df = pd.read_excel(path + folder + filename)\n",
    "df = df.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_weights(x):\n",
    "    return 1.0 / x\n",
    "\n",
    "\n",
    "df[\"Polarity\"] = df[\"Polarity\"] - 1\n",
    "X, y = df[\"Review\"], df[\"Polarity\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "datasets = pd.DataFrame({\"X_train\": X_train, \"y_train\": y_train})\n",
    "\n",
    "test = pd.DataFrame({\"X_test\": X_test, \"y_test\": y_test})\n",
    "\n",
    "print(f\"Stratified sampling mode : \")\n",
    "datasets[\"freq\"] = datasets.groupby(\"y_train\")[\"y_train\"].transform(\"count\")\n",
    "test[\"freq\"] = test.groupby(\"y_test\")[\"y_test\"].transform(\"count\")\n",
    "datasets_balanced = datasets.sample(\n",
    "    n=len(datasets), replace=True, weights=datasets[\"freq\"].apply(to_weights)\n",
    ").copy()\n",
    "test_balanced = test.sample(\n",
    "    n=len(test), replace=True, weights=test[\"freq\"].apply(to_weights)\n",
    ").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The values of the first 5 rows are : \")\n",
    "datasets_balanced.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis (Polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(X_batch, min_length=0, max_length=308, tensor_mode=True):\n",
    "    X_batch = str(X_batch).lower()\n",
    "    X_batch = re.sub(r\"[á']\", r\"a\", X_batch)\n",
    "    X_batch = re.sub(r\"[é']\", r\"e\", X_batch)\n",
    "    X_batch = re.sub(r\"[í']\", r\"i\", X_batch)\n",
    "    X_batch = re.sub(r\"[ó']\", r\"o\", X_batch)\n",
    "    X_batch = re.sub(r\"[ú']\", r\"u\", X_batch)\n",
    "    # X_batch = ''.join(i for i, _ in itertools.groupby(X_batch))\n",
    "    X_batch = re.sub(r\"(.)\\1+\", r\"\\1\", X_batch)\n",
    "    X_batch = tf.strings.substr(X_batch, min_length, max_length)\n",
    "    X_batch = tf.strings.regex_replace(X_batch, r\"[^a-zA-Zñ']\", r\" \")\n",
    "    X_batch = tf.strings.regex_replace(X_batch, r\"[^\\w\\s]\", r\"\")\n",
    "    X_batch = tf.strings.split(X_batch)\n",
    "    X_batch = [str(w).replace(\"b'\", \"\").replace(\"'\", \"\") for w in X_batch.numpy()]\n",
    "    if tensor_mode:\n",
    "        n = len(X_batch)\n",
    "        X_add = [\"\"] * (max_length - n)\n",
    "        X_batch += X_add\n",
    "        return tf.convert_to_tensor(X_batch)\n",
    "    else:\n",
    "        return X_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"vocab.pkl\"):\n",
    "    with open(\"vocab.pkl\", \"rb\") as file:\n",
    "        vocabulary = pickle.load(file)\n",
    "else:\n",
    "    vocabulary = Counter()\n",
    "    reviews = df[[\"Review\"]].iloc[:, 0].apply(preprocess, tensor_mode=False)\n",
    "    for X_batch in reviews:\n",
    "        vocabulary.update(X_batch)\n",
    "\n",
    "    with open(\"vocab.pkl\", \"wb\") as file:\n",
    "        pickle.dump(vocabulary, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 5 most common words\n",
    "vocabulary.most_common()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total size of the vocabulary : \", \"{:,}\".format(len(vocabulary.most_common())))\n",
    "print(\"-------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's truncate the vocabulary, keeping only the 10,000 most common words\n",
    "vocab_size = 10000\n",
    "truncated_vocabulary = [word for word, count in vocabulary.most_common()[:vocab_size]]\n",
    "\n",
    "# now we add a preprocessing step to replace each work with its ID\n",
    "words = tf.constant(truncated_vocabulary)\n",
    "words_ids = tf.range(len(truncated_vocabulary), dtype=tf.int64)\n",
    "vocab_init = tf.lookup.KeyValueTensorInitializer(words, words_ids)\n",
    "# we will create a lookup table for this, using 1,000 out-of-vocabulary (oov) buckets\n",
    "num_oov_buckets = 1000\n",
    "table = tf.lookup.StaticVocabularyTable(vocab_init, num_oov_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"1) Example of use.\")\n",
    "print(\"-------------------------------------------------------\")\n",
    "text = \"Muy buena la atención de principio a fin en el restaurante Serratta. Por parte de Jonathan. Recomendado.\"\n",
    "# print('preprocess text : ', preprocess(text))\n",
    "# table.lookup(preprocess(text)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 5\n",
    "\n",
    "\n",
    "# now we create the encode_words() function that uses the table we just built\n",
    "def encode_words(X_batch):\n",
    "    if X_batch.isnumeric():\n",
    "        X_batch = \"\"\n",
    "    return list(table[preprocess(X_batch)].numpy())\n",
    "\n",
    "\n",
    "datasets_balanced = datasets_balanced.drop(columns=[\"freq\"])\n",
    "test_balanced = test_balanced.drop(columns=[\"freq\"])\n",
    "training_sentences = datasets_balanced[\"X_train\"].to_list()\n",
    "testing_sentences = test_balanced[\"X_test\"].to_list()\n",
    "\n",
    "embed_size = 16\n",
    "max_length = 32\n",
    "trunc_type = \"post\"\n",
    "padding_type = \"post\"\n",
    "oov_tok = \"\"\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "\n",
    "padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type\n",
    ")\n",
    "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "testing_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type\n",
    ")\n",
    "padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"train_x.pkl\"):\n",
    "    with open(\"train_x.pkl\", \"rb\") as file:\n",
    "        train_x = pickle.load(file)\n",
    "\n",
    "    with open(\"test_x.pkl\", \"rb\") as file:\n",
    "        test_x = pickle.load(file)\n",
    "else:\n",
    "    train_x = np.array(\n",
    "        [encode_words(sentence) for sentence in datasets_balanced[\"X_train\"].to_list()]\n",
    "    )\n",
    "    test_x = np.array([encode_words(sentence) for sentence in test_balanced[\"X_test\"].to_list()])\n",
    "\n",
    "    with open(\"train_x.pkl\", \"wb\") as file:\n",
    "        pickle.dump(train_x, file)\n",
    "\n",
    "    with open(\"test_x.pkl\", \"wb\") as file:\n",
    "        pickle.dump(test_x, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"hub_train_x.pkl\"):\n",
    "    with open(\"hub_train_x.pkl\", \"rb\") as file:\n",
    "        hub_train_x = pickle.load(file)\n",
    "\n",
    "    with open(\"hub_test_x.pkl\", \"rb\") as file:\n",
    "        hub_test_x = pickle.load(file)\n",
    "else:\n",
    "    hub_train_x = np.array([sentence for sentence in datasets_balanced[\"X_train\"].to_list()])\n",
    "    hub_test_x = np.array([sentence for sentence in test_balanced[\"X_test\"].to_list()])\n",
    "\n",
    "    try:\n",
    "        with open(\"hub_train_x.pkl\", \"wb\") as file:\n",
    "            pickle.dump(hub_train_x, file)\n",
    "\n",
    "        with open(\"hub_test_x.pkl\", \"wb\") as file:\n",
    "            pickle.dump(hub_test_x, file)\n",
    "    except MemoryError:\n",
    "        print(\"It is not possible to save the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = datasets_balanced[\"y_train\"]\n",
    "train_y = (tf.one_hot(train_y, depth)).numpy()\n",
    "\n",
    "test_y = test_balanced[\"y_test\"]\n",
    "test_y = (tf.one_hot(test_y, depth)).numpy()\n",
    "\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reusing Pretrained Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF Hub repository (https://tfhub.dev)\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        hub.KerasLayer(\n",
    "            \"https://tfhub.dev/google/tf2-preview/nnlm-es-dim50/1\",\n",
    "            output_shape=[50],\n",
    "            input_shape=[],\n",
    "            dtype=tf.string,\n",
    "        ),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(5, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(hub_train_x, train_y, epochs=35, validation_data=(hub_test_x, test_y))\n",
    "\n",
    "\n",
    "def plot_history(history):\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist[\"epoch\"] = history.epoch\n",
    "    hist.tail()\n",
    "\n",
    "    # plot history\n",
    "    plt.plot(history.history[\"loss\"], label=\"Train Error\")\n",
    "    plt.plot(history.history[\"val_loss\"], label=\"Validation Error\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_history(history)\n",
    "model.save(\"saved_model/hub_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at last we create the model and train it\n",
    "\n",
    "custom_model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Embedding(\n",
    "            vocab_size, embed_size, input_shape=[None], input_length=max_length\n",
    "        ),\n",
    "        tf.keras.layers.GRU(128, return_sequences=True),\n",
    "        tf.keras.layers.GRU(128),\n",
    "        tf.keras.layers.Dense(5, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "custom_model.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = custom_model.fit(padded, train_y, epochs=5, validation_data=(testing_padded, test_y))\n",
    "\n",
    "plot_history(history)\n",
    "custom_model.save(\"saved_model/custom_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerformanceMeasures:\n",
    "    \"\"\"Class with methods to measure performance\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    # Performance measure Res_T\n",
    "    def f_mean(self, y_true: ndarray, y_pred: ndarray, labels: list) -> None:\n",
    "        n = len(labels)\n",
    "\n",
    "        F_vec = f1_score(y_true, y_pred, average=None, labels=labels)\n",
    "        a = np.sum(F_vec)\n",
    "\n",
    "        for i in range(len(F_vec)):\n",
    "            print(\"F-measure of label \", labels[i], \" -> \", F_vec[i])\n",
    "\n",
    "        print(\"Mean of F-measure -> \", a / n)\n",
    "\n",
    "    # Performance measure Res_P\n",
    "    def resp(self, y_true: ndarray, y_pred: ndarray, labels: list) -> None:\n",
    "        # We initialize sum counters\n",
    "        sum1 = 0\n",
    "        sum2 = 0\n",
    "\n",
    "        # Calculamos T_C\n",
    "        T_C = len(y_true)\n",
    "        for i in range(len(labels)):\n",
    "            # We calculate instances of the classes and their F-measures\n",
    "            sum1 += (1 - ((y_true == labels[i]).sum() / T_C)) * self._fi_measure(\n",
    "                y_true, y_pred, labels, i\n",
    "            )\n",
    "            sum2 += 1 - ((y_true == labels[i]).sum()) / T_C\n",
    "\n",
    "        # Print the metric corresponding to the prediction vector\n",
    "        print(\"Metric Res_p ->\", sum1 / sum2)\n",
    "\n",
    "    def _fi_measure(self, y_true: ndarray, y_pred: ndarray, labels: list, i: int) -> int:\n",
    "        F_vec = f1_score(y_true, y_pred, average=None, labels=labels)\n",
    "\n",
    "        return F_vec[i]  # We return the position of the f1-score corresponding to the label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of the model tfhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [0, 1, 2, 3, 4]\n",
    "prediction = model.predict(hub_test_x)\n",
    "prediction = tf.argmax(prediction, axis=1).numpy()\n",
    "ground_true = tf.argmax(test_y, 1).numpy()\n",
    "\n",
    "metrics = PerformanceMeasures()\n",
    "metrics.f_mean(ground_true, prediction, labels)\n",
    "metrics.resp(ground_true, prediction, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of the custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = custom_model.predict(testing_padded)\n",
    "prediction = tf.argmax(prediction, axis=1).numpy()\n",
    "\n",
    "metrics.f_mean(ground_true, prediction, labels)\n",
    "metrics.resp(ground_true, prediction, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
